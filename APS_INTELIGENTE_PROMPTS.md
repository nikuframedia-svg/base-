# üöÄ APS INTELIGENTE ON-PREM - SUPER PROMPTS DE DESENVOLVIMENTO

**Reposit√≥rio:** https://github.com/nikuframedia-svg/base-  
**Data:** 2025-01-18  
**Objetivo:** Prompts super inovadores e detalhados para desenvolvimento de funcionalidades avan√ßadas

---

## üìã √çNDICE DE FUNCIONALIDADES

1. ‚úÖ Planeamento Encadeado (Chained Planning) - **PARCIALMENTE IMPLEMENTADO**
2. ‚ö†Ô∏è LLM Local com Fine-Tuning LoRA - **B√ÅSICO IMPLEMENTADO**
3. ‚ö†Ô∏è Simulador What-If Conversacional Avan√ßado - **B√ÅSICO IMPLEMENTADO**
4. ‚ö†Ô∏è Gera√ß√£o Autom√°tica de Relat√≥rios pelo LLM - **PARCIALMENTE IMPLEMENTADO**
5. ‚ö†Ô∏è M√≥dulo ML/AutoML Offline Avan√ßado - **PARCIALMENTE IMPLEMENTADO**
6. ‚ö†Ô∏è Visualiza√ß√µes e Dashboards Avan√ßados - **PARCIALMENTE IMPLEMENTADO**
7. ‚ùå Planeamento de Longo Prazo Estrat√©gico - **N√ÉO IMPLEMENTADO**
8. ‚ö†Ô∏è Integra√ß√£o ERP/MES Bidirecional Avan√ßada - **B√ÅSICO IMPLEMENTADO**

---

## 1. ‚úÖ PLANEAMENTO ENCADEADO (CHAINED PLANNING) - MELHORIAS

### Status Atual
- ‚úÖ `backend/planning/chained_scheduler.py` existe (617 linhas)
- ‚úÖ Modelo MILP b√°sico implementado
- ‚ö†Ô∏è Faltam: otimiza√ß√£o de buffers din√¢mica, sincroniza√ß√£o multi-cadeia, WIP optimization

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: PLANEAMENTO ENCADEADO AVAN√áADO COM OTIMIZA√á√ÉO DIN√ÇMICA DE BUFFERS

## CONTEXTO
Implementar um sistema de planeamento encadeado (Chained Planning) que sincroniza m√∫ltiplas m√°quinas/etapas em fluxo cont√≠nuo, com otimiza√ß√£o din√¢mica de buffers e gest√£o de WIP (Work In Progress).

## MODELO MATEM√ÅTICO AVAN√áADO

### 1. Formula√ß√£o MILP Multi-Objetivo com Buffers Din√¢micos

**Sets:**
- J = {1, ..., n} : Jobs (ordens)
- M = {1, ..., m} : M√°quinas na cadeia
- K = {1, ..., k} : Cadeias de produ√ß√£o
- T = {1, ..., T} : Per√≠odos temporais discretos

**Variables:**
- S_{j,k,m} : Start time do job j na cadeia k, m√°quina m
- C_{j,k,m} : Completion time do job j na cadeia k, m√°quina m
- y_{i,j,k,m} ‚àà {0,1} : 1 se job i precede job j na m√°quina m da cadeia k
- B_{k,m,t} ‚â• 0 : Buffer size (WIP) na m√°quina m da cadeia k no per√≠odo t
- b_{k,m} ‚â• 0 : Buffer time otimizado entre m√°quina m e m+1 na cadeia k
- w_{j,k} ‚àà {0,1} : 1 se job j √© alocado √† cadeia k

**Parameters:**
- p_{j,k,m} : Processing time do job j na m√°quina m da cadeia k
- d_j : Due date do job j
- b_min_{k,m} : Buffer m√≠nimo entre m√°quina m e m+1
- b_max_{k,m} : Buffer m√°ximo permitido
- WIP_max_{k,m} : Capacidade m√°xima de WIP na m√°quina m
- c_buffer : Custo de manter buffer (‚Ç¨/unidade/hora)
- c_tardiness : Custo de atraso (‚Ç¨/hora)
- c_makespan : Peso do makespan no objetivo

**Constraints:**

(1) Completion: C_{j,k,m} = S_{j,k,m} + p_{j,k,m}  ‚àÄj,k,m

(2) Precedence encadeada: S_{j,k,m+1} ‚â• C_{j,k,m} + b_{k,m}  ‚àÄj,k,m<|M_k|

(3) No overlap: S_{j,k,m} ‚â• C_{i,k,m} - M(1 - y_{i,j,k,m})  ‚àÄi‚â†j,k,m

(4) Sequencing: y_{i,j,k,m} + y_{j,i,k,m} = 1  ‚àÄi<j,k,m

(5) Buffer bounds: b_min_{k,m} ‚â§ b_{k,m} ‚â§ b_max_{k,m}  ‚àÄk,m

(6) WIP constraint: B_{k,m,t} ‚â§ WIP_max_{k,m}  ‚àÄk,m,t

(7) WIP dynamics: B_{k,m,t+1} = B_{k,m,t} + arrivals_{k,m,t} - completions_{k,m,t}

(8) Single chain assignment: Œ£_k w_{j,k} = 1  ‚àÄj

**Objective Function (Multi-Objective):**

min  Œ±‚ÇÅ¬∑C_max + Œ±‚ÇÇ¬∑Œ£_j w_j¬∑max(0, C_{j,k,|M_k|} - d_j) + Œ±‚ÇÉ¬∑Œ£_{k,m} c_buffer¬∑B_{k,m} + Œ±‚ÇÑ¬∑Œ£_{k,m} |b_{k,m} - b_optimal_{k,m}|

Onde:
- C_max = max_{j,k} C_{j,k,|M_k|}  (makespan global)
- b_optimal_{k,m} = f(WIP_{k,m}, throughput_{k,m})  (buffer √≥timo calculado dinamicamente)

### 2. Algoritmo de Otimiza√ß√£o de Buffers Din√¢mica

Implementar algoritmo h√≠brido:
- **Fase 1**: Resolver MILP com buffers fixos (valores iniciais)
- **Fase 2**: Usar **Gradient-Based Optimization** para ajustar buffers:
  - Calcular gradiente: ‚àÇ(objective)/‚àÇb_{k,m}
  - Aplicar **Adam Optimizer** adaptado para buffers discretos
  - Iterar at√© converg√™ncia ou timeout

**F√≥rmula de Buffer √ìtimo:**
b_optimal_{k,m} = argmin_b [c_buffer¬∑b + c_tardiness¬∑E[Tardiness|b] + c_WIP¬∑E[WIP|b]]

Onde E[¬∑] √© esperan√ßa calculada via simula√ß√£o estoc√°stica.

### 3. Sincroniza√ß√£o Multi-Cadeia

Para m√∫ltiplas cadeias que convergem/divergem:

**Convergence Point:**
- Jobs de cadeias diferentes chegam ao mesmo recurso
- Usar **Priority Queue** com **Critical Ratio** din√¢mico
- CR_{j} = (d_j - t_now) / remaining_processing_time

**Divergence Point:**
- Jobs saem de uma m√°quina para m√∫ltiplas cadeias
- Usar **Load Balancing Algorithm**:
  - Balancear carga: min Œ£_k |load_k - avg_load|
  - Considerar capacidades e tempos de setup

## IMPLEMENTA√á√ÉO T√âCNICA

### Arquitetura
1. **ChainedSchedulerAdvanced** class
   - Herda de `ChainedScheduler` existente
   - Adiciona m√©todos: `optimize_buffers()`, `sync_multi_chain()`, `calculate_wip()`

2. **BufferOptimizer** class
   - M√©todo: `optimize_dynamic_buffers(chain_config, historical_data)`
   - Usa scipy.optimize.minimize com m√©todo 'L-BFGS-B'
   - Integra simula√ß√£o estoc√°stica para E[¬∑]

3. **MultiChainSynchronizer** class
   - M√©todo: `synchronize_chains(chains, convergence_points, divergence_points)`
   - Implementa algoritmo de balanceamento de carga

### Integra√ß√£o com LLM
- LLM interpreta comandos: "Ativa modo encadeado A‚ÜíB‚ÜíC com buffer 30min"
- LLM explica decis√µes: "Buffer otimizado para 45min para reduzir WIP em 20%"

## TESTES
- Testar com 3 cadeias, 5 m√°quinas cada
- Validar redu√ß√£o de makespan vs planeamento independente
- Verificar WIP dentro de limites
- Medir tempo de execu√ß√£o (< 60s para 100 jobs)

## FICHEIRO DE SA√çDA
`backend/planning/chained_scheduler_advanced.py`
```

---

## 2. ‚ö†Ô∏è LLM LOCAL COM FINE-TUNING LORA - MELHORIAS

### Status Atual
- ‚úÖ `backend/app/llm/local.py` existe (b√°sico)
- ‚ùå Falta: Fine-tuning LoRA, vector database, contexto industrial

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: LLM LOCAL AVAN√áADO COM FINE-TUNING LORA E VECTOR DATABASE

## CONTEXTO
Implementar um sistema LLM local (LLaMA/Mistral) com fine-tuning LoRA para dom√≠nio industrial, integrado com vector database para contexto espec√≠fico da f√°brica.

## ARQUITETURA AVAN√áADA

### 1. Fine-Tuning LoRA (Low-Rank Adaptation)

**Modelo Base:**
- LLaMA 2 7B ou Mistral 7B (quantizado 4-bit)
- Rodar localmente via llama.cpp ou Ollama

**LoRA Configuration:**
- Rank r = 16 (trade-off qualidade/velocidade)
- Alpha = 32 (scaling factor)
- Target modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
- Learning rate: 1e-4
- Batch size: 4
- Epochs: 3-5

**Dataset de Treino:**
- 1000+ exemplos de comandos industriais
- Formato: {"instruction": "...", "input": "...", "output": "..."}
- Exemplos:
  - "Adiciona m√°quina 305B com tempo ciclo 20% mais r√°pido"
  - "Explica por que ordem #1234 est√° atrasada"
  - "Compara cen√°rio baseline vs novo cen√°rio"

**Training Script:**
```python
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForCausalLM, AutoTokenizer

lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
)

model = AutoModelForCausalLM.from_pretrained(
    "mistralai/Mistral-7B-v0.1",
    load_in_4bit=True,
    device_map="auto"
)

model = get_peft_model(model, lora_config)
# Training loop...
```

### 2. Vector Database para Contexto Industrial

**Embeddings:**
- Usar `sentence-transformers` (all-MiniLM-L6-v2)
- Embeddings de: ordens, m√°quinas, produtos, hist√≥rico de decis√µes

**Vector Store:**
- Usar **ChromaDB** ou **FAISS** (local, on-prem)
- Indexar: 10k+ documentos industriais
- Similarity search: cosine similarity

**RAG (Retrieval-Augmented Generation):**
1. Query do utilizador ‚Üí embedding
2. Vector search ‚Üí top 5 documentos relevantes
3. Context injection ‚Üí prompt com contexto
4. LLM gera resposta baseada em contexto

**Exemplo:**
```python
from sentence_transformers import SentenceTransformer
import chromadb

# Inicializar
embedder = SentenceTransformer('all-MiniLM-L6-v2')
client = chromadb.Client()
collection = client.create_collection("industrial_knowledge")

# Indexar conhecimento
docs = ["M√°quina 305: tempo ciclo 45min, setup 15min", ...]
embeddings = embedder.encode(docs)
collection.add(embeddings=embeddings, documents=docs)

# Query
query_embedding = embedder.encode("Qual tempo ciclo m√°quina 305?")
results = collection.query(query_embeddings=[query_embedding], n_results=3)
```

### 3. Prompt Engineering Avan√ßado

**Template de Prompt:**
```
Voc√™ √© um assistente especializado em planeamento de produ√ß√£o industrial (APS).

CONTEXTO DA F√ÅBRICA:
{context_from_vector_db}

DADOS ATUAIS DO PLANO:
{current_plan_summary}

HIST√ìRICO DE DECIS√ïES:
{recent_decisions}

INSTRU√á√ÉO DO UTILIZADOR:
{user_query}

RESPOSTA (seja t√©cnico mas claro):
```

### 4. Integra√ß√£o com APS

**Endpoints:**
- `/api/llm/chat` - Chat geral
- `/api/llm/explain` - Explicar decis√£o
- `/api/llm/command` - Interpretar comando NL ‚Üí a√ß√£o APS
- `/api/llm/report` - Gerar relat√≥rio autom√°tico

**Command Parser:**
```python
class IndustrialCommandParser:
    def parse(self, text: str) -> APSAction:
        # Usar LLM para extrair:
        # - Tipo de a√ß√£o (add_machine, remove_machine, etc.)
        # - Par√¢metros (machine_id, date, etc.)
        # - Valida√ß√£o de seguran√ßa
```

## IMPLEMENTA√á√ÉO

### Ficheiros a Criar:
1. `backend/app/llm/lora_trainer.py` - Fine-tuning LoRA
2. `backend/app/llm/vector_store.py` - Vector database
3. `backend/app/llm/rag_engine.py` - RAG implementation
4. `backend/app/llm/command_parser.py` - NL command parser
5. `backend/app/llm/prompt_templates.py` - Templates avan√ßados

### Depend√™ncias:
- `peft` - LoRA fine-tuning
- `sentence-transformers` - Embeddings
- `chromadb` ou `faiss-cpu` - Vector store
- `llama-cpp-python` ou `ollama` - LLM local

## TESTES
- Validar compreens√£o de termos industriais
- Testar RAG com queries espec√≠ficas
- Medir lat√™ncia (< 2s por resposta)
- Validar seguran√ßa (n√£o executar comandos perigosos)

## FICHEIRO DE SA√çDA
`backend/app/llm/advanced_llm_system.py`
```

---

## 3. ‚ö†Ô∏è SIMULADOR WHAT-IF CONVERSACIONAL AVAN√áADO

### Status Atual
- ‚úÖ `backend/app/api/whatif.py` existe (b√°sico)
- ‚ùå Falta: Parser NL avan√ßado, reconfigura√ß√£o din√¢mica, compara√ß√£o visual

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: SIMULADOR WHAT-IF CONVERSACIONAL COM RECONFIGURA√á√ÉO DIN√ÇMICA

## CONTEXTO
Implementar um simulador What-If que permite reconfigurar a f√°brica via comandos em linguagem natural, recalcular planos instantaneamente e comparar cen√°rios.

## MODELO MATEM√ÅTICO DE RECONFIGURA√á√ÉO

### 1. Formaliza√ß√£o de Altera√ß√µes de Cen√°rio

**State Space:**
S = {M, R, C, P, T, O}

Onde:
- M = {m‚ÇÅ, ..., m‚Çô} : Conjunto de m√°quinas
- R = {r‚ÇÅ, ..., r‚Çñ} : Conjunto de rotas
- C = {c‚ÇÅ, ..., c‚Çó} : Calend√°rios (turnos, manuten√ß√£o)
- P = {p‚ÇÅ, ..., p‚Çò} : Par√¢metros de processo
- T = {t‚ÇÅ, ..., t‚Çí} : Tempos (ciclo, setup)
- O = {o‚ÇÅ, ..., o‚Çö} : Operadores

**Transition Function:**
Œ¥: S √ó Action ‚Üí S'

**Actions:**
- ADD_MACHINE(m, specs)
- REMOVE_MACHINE(m, date)
- REPLACE_MACHINE(m_old, m_new, date)
- MODIFY_PARAMETER(p, new_value, date)
- CHANGE_ROUTING(product, old_route, new_route)
- ADD_SHIFT(machine, shift_config, date)
- REMOVE_SHIFT(machine, shift_id, date)

### 2. Algoritmo de Reconfigura√ß√£o Incremental

**Incremental Replanning:**
- Em vez de recalcular tudo, recalcular apenas afetados
- Usar **Dependency Graph** para identificar impactos

**Dependency Graph:**
G = (V, E) onde:
- V = {jobs, machines, operations}
- E = {(u,v) | u depende de v}

**Algoritmo:**
```python
def incremental_replan(base_plan, changes):
    affected = set()
    for change in changes:
        affected.update(get_dependent_nodes(change))
    
    # Recalcular apenas afetados
    new_plan = base_plan.copy()
    for node in affected:
        new_plan[node] = reschedule(node, constraints)
    
    return new_plan
```

### 3. Compara√ß√£o de Cen√°rios (M√©tricas)

**M√©tricas de Compara√ß√£o:**
- Makespan: ŒîC_max = C_max_new - C_max_base
- Throughput: ŒîTP = TP_new - TP_base
- Utilization: ŒîU_m = U_m_new - U_m_base
- Tardiness: ŒîT = Œ£(max(0, C_j - d_j))
- WIP: ŒîWIP = WIP_new - WIP_base
- Cost: ŒîCost = Cost_new - Cost_base

**Score de Melhoria:**
Score = w‚ÇÅ¬∑(ŒîTP/TP_base) + w‚ÇÇ¬∑(-ŒîT/T_base) + w‚ÇÉ¬∑(-ŒîCost/Cost_base)

### 4. Natural Language Command Parser

**Usar LLM + Structured Output:**
```python
class WhatIfCommandParser:
    def parse(self, text: str) -> List[Action]:
        prompt = f"""
        Parse o seguinte comando de reconfigura√ß√£o industrial:
        "{text}"
        
        Extraia a√ß√µes no formato JSON:
        {{
            "actions": [
                {{
                    "type": "ADD_MACHINE|REMOVE_MACHINE|...",
                    "target": "machine_id",
                    "params": {{...}},
                    "date": "YYYY-MM-DD"
                }}
            ]
        }}
        """
        
        response = llm.generate(prompt)
        return parse_json(response)
```

## IMPLEMENTA√á√ÉO

### Classes Principais:

1. **WhatIfSimulator** class
   - `simulate_scenario(changes: List[Action]) -> ScenarioResult`
   - `compare_scenarios(base, new) -> ComparisonReport`
   - `apply_changes(base_plan, changes) -> new_plan`

2. **ScenarioReconfigurator** class
   - `add_machine(specs) -> Action`
   - `remove_machine(machine_id, date) -> Action`
   - `modify_parameter(param, value, date) -> Action`
   - `change_routing(product, new_route) -> Action`

3. **ScenarioComparator** class
   - `compare_metrics(base, new) -> ComparisonMetrics`
   - `identify_bottlenecks(base, new) -> List[Bottleneck]`
   - `calculate_improvement_score(base, new) -> float`

4. **NLCommandParser** class
   - `parse_command(text: str) -> List[Action]`
   - `validate_actions(actions) -> ValidationResult`

### Integra√ß√£o com LLM:
- LLM interpreta: "Adiciona m√°quina 305B 20% mais r√°pida a partir de Maio"
- LLM explica: "M√°quina 305B reduz makespan em 15% mas cria novo gargalo em 310"

## TESTES
- Testar 10+ comandos NL diferentes
- Validar reconfigura√ß√£o incremental (< 5s)
- Verificar compara√ß√£o de m√©tricas
- Testar seguran√ßa (n√£o permitir a√ß√µes destrutivas sem confirma√ß√£o)

## FICHEIRO DE SA√çDA
`backend/simulation/whatif_advanced.py`
```

---

## 4. ‚ö†Ô∏è GERA√á√ÉO AUTOM√ÅTICA DE RELAT√ìRIOS PELO LLM

### Status Atual
- ‚ö†Ô∏è Parcialmente implementado em `backend/app/insights/engine.py`
- ‚ùå Falta: Templates avan√ßados, an√°lise financeira, relat√≥rios executivos

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: GERA√á√ÉO AUTOM√ÅTICA DE RELAT√ìRIOS EXECUTIVOS E T√âCNICOS

## CONTEXTO
Implementar sistema de gera√ß√£o autom√°tica de relat√≥rios usando LLM, com templates avan√ßados, an√°lise financeira e visualiza√ß√µes integradas.

## ARQUITETURA DE GERA√á√ÉO DE RELAT√ìRIOS

### 1. Template System Avan√ßado

**Tipos de Relat√≥rios:**
- Executive Summary (1 p√°gina)
- Technical Analysis (detalhado)
- Comparison Report (baseline vs cen√°rio)
- Financial Impact Analysis
- Bottleneck Analysis
- Improvement Recommendations

**Template Structure:**
```python
class ReportTemplate:
    sections: List[Section]
    metrics: List[Metric]
    visualizations: List[VizConfig]
    llm_prompts: Dict[str, str]
```

### 2. An√°lise Financeira Autom√°tica

**M√©tricas Financeiras:**
- ROI (Return on Investment)
- Payback Period
- NPV (Net Present Value)
- Cost per Unit
- Margin Impact

**C√°lculos:**
```python
def calculate_roi(investment, annual_savings, years=5):
    total_savings = sum([annual_savings * (1 + discount_rate)**-i 
                        for i in range(1, years+1)])
    roi = (total_savings - investment) / investment * 100
    return roi

def calculate_payback(investment, monthly_savings):
    return investment / monthly_savings  # meses
```

### 3. LLM-Powered Report Generation

**Prompt Template:**
```
Voc√™ √© um analista industrial experiente. Gere um relat√≥rio executivo baseado nos dados:

DADOS DO PLANO BASE:
{base_plan_metrics}

DADOS DO NOVO CEN√ÅRIO:
{new_scenario_metrics}

COMPARA√á√ÉO:
{comparison_metrics}

Gere um relat√≥rio com:
1. Executive Summary (3 par√°grafos)
2. Principais Melhorias (top 5)
3. Principais Riscos (top 3)
4. Recomenda√ß√µes (3-5 a√ß√µes)
5. An√°lise Financeira (ROI, Payback)

Formato: Markdown profissional
```

### 4. Visualiza√ß√µes Integradas

**Gerar gr√°ficos localmente:**
- Gantt comparativo (matplotlib/plotly)
- Heatmaps de utiliza√ß√£o
- Gr√°ficos de barras (antes/depois)
- Proje√ß√µes temporais

**Integra√ß√£o:**
```python
def generate_report_with_viz(data, template):
    report_text = llm.generate_report(data, template)
    visualizations = generate_charts(data)
    return combine_report(report_text, visualizations)
```

## IMPLEMENTA√á√ÉO

### Classes:

1. **ReportGenerator** class
   - `generate_executive_summary(plan_data) -> str`
   - `generate_technical_analysis(plan_data) -> str`
   - `generate_comparison_report(base, new) -> str`
   - `generate_financial_analysis(scenario) -> FinancialReport`

2. **FinancialAnalyzer** class
   - `calculate_roi(investment, savings) -> float`
   - `calculate_payback(investment, monthly_savings) -> float`
   - `estimate_cost_impact(changes) -> CostImpact`

3. **ReportTemplateEngine** class
   - `load_template(template_name) -> Template`
   - `render_template(template, data) -> str`
   - `add_visualization(report, viz_config) -> Report`

## TESTES
- Validar qualidade dos relat√≥rios (review manual)
- Testar c√°lculos financeiros (valida√ß√£o com Excel)
- Verificar integra√ß√£o de visualiza√ß√µes
- Medir tempo de gera√ß√£o (< 10s)

## FICHEIRO DE SA√çDA
`backend/reporting/llm_report_generator.py`
```

---

## 5. ‚ö†Ô∏è M√ìDULO ML/AUTOML OFFLINE AVAN√áADO

### Status Atual
- ‚ö†Ô∏è Parcialmente implementado (XGBoost, ARIMA b√°sicos)
- ‚ùå Falta: AutoML completo (H2O.ai), detec√ß√£o de anomalias avan√ßada, ensemble methods

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: AUTOML OFFLINE AVAN√áADO COM H2O.AI E ENSEMBLE METHODS

## CONTEXTO
Implementar m√≥dulo AutoML completo usando H2O.ai para sele√ß√£o autom√°tica de modelos, com detec√ß√£o de anomalias e ensemble methods.

## ARQUITETURA AUTOML

### 1. H2O.ai AutoML Integration

**Configura√ß√£o:**
```python
import h2o
from h2o.automl import H2OAutoML

h2o.init()

# Preparar dados
train_frame = h2o.H2OFrame(train_data)
test_frame = h2o.H2OFrame(test_data)

# AutoML
aml = H2OAutoML(
    max_models=20,
    max_runtime_secs=3600,  # 1 hora
    seed=42,
    stopping_metric="RMSE",
    stopping_tolerance=0.001,
    stopping_rounds=3,
    sort_metric="RMSE"
)

aml.train(
    x=features,
    y=target,
    training_frame=train_frame,
    validation_frame=test_frame
)

# Melhor modelo
best_model = aml.leader
```

### 2. Ensemble Methods

**Stacking Ensemble:**
- Base models: XGBoost, Random Forest, Neural Network
- Meta-learner: Linear Regression ou XGBoost
- Cross-validation para evitar overfitting

**Blending:**
- Treinar modelos em diferentes folds
- Combinar predi√ß√µes com pesos otimizados

**C√≥digo:**
```python
class EnsemblePredictor:
    def __init__(self):
        self.base_models = [
            XGBoostRegressor(),
            RandomForestRegressor(),
            MLPRegressor()
        ]
        self.meta_learner = LinearRegression()
    
    def fit(self, X, y):
        # Treinar base models
        base_predictions = []
        for model in self.base_models:
            model.fit(X, y)
            pred = model.predict(X)
            base_predictions.append(pred)
        
        # Treinar meta-learner
        meta_X = np.column_stack(base_predictions)
        self.meta_learner.fit(meta_X, y)
    
    def predict(self, X):
        base_preds = [m.predict(X) for m in self.base_models]
        meta_X = np.column_stack(base_preds)
        return self.meta_learner.predict(meta_X)
```

### 3. Detec√ß√£o de Anomalias Avan√ßada

**Isolation Forest + LSTM Autoencoder:**
```python
from sklearn.ensemble import IsolationForest
from tensorflow.keras.models import Model

# Isolation Forest
iso_forest = IsolationForest(contamination=0.1)
anomalies_iso = iso_forest.fit_predict(data)

# LSTM Autoencoder
class LSTMAutoencoder:
    def __init__(self, seq_length=10, latent_dim=32):
        # Encoder
        encoder_input = Input(shape=(seq_length, n_features))
        encoded = LSTM(latent_dim)(encoder_input)
        
        # Decoder
        decoded = RepeatVector(seq_length)(encoded)
        decoded = LSTM(n_features, return_sequences=True)(decoded)
        
        self.autoencoder = Model(encoder_input, decoded)
        self.autoencoder.compile(optimizer='adam', loss='mse')
    
    def detect_anomalies(self, data, threshold=0.1):
        reconstructed = self.autoencoder.predict(data)
        mse = np.mean((data - reconstructed)**2, axis=1)
        anomalies = mse > threshold
        return anomalies
```

### 4. Previs√µes Avan√ßadas

**Time Series Forecasting com AutoML:**
- Auto-ARIMA (pmdarima)
- Prophet (Facebook)
- N-BEATS (NeuralForecast)
- Auto-sele√ß√£o baseada em AIC/BIC

**C√≥digo:**
```python
from pmdarima import auto_arima
from prophet import Prophet
from neuralforecast import NeuralForecast
from neuralforecast.models import NBEATS

def auto_forecast(series, horizon=12):
    # Tentar Auto-ARIMA
    arima_model = auto_arima(series, seasonal=True, m=12)
    arima_forecast = arima_model.predict(horizon)
    
    # Tentar Prophet
    prophet_df = pd.DataFrame({
        'ds': series.index,
        'y': series.values
    })
    prophet_model = Prophet()
    prophet_model.fit(prophet_df)
    prophet_forecast = prophet_model.predict(
        prophet_model.make_future_dataframe(periods=horizon)
    )
    
    # Tentar N-BEATS
    nbeats = NBEATS(h=horizon, input_size=24)
    nbeats_forecast = nbeats.predict(series)
    
    # Ensemble (m√©dia ponderada)
    final_forecast = (
        0.4 * arima_forecast +
        0.3 * prophet_forecast +
        0.3 * nbeats_forecast
    )
    
    return final_forecast
```

## IMPLEMENTA√á√ÉO

### Classes:

1. **AutoMLPredictor** class
   - `train_automl(data, target) -> H2OAutoML`
   - `predict(model, data) -> predictions`
   - `get_feature_importance(model) -> Dict`

2. **EnsemblePredictor** class
   - `create_ensemble(base_models, meta_learner) -> Ensemble`
   - `fit_ensemble(X, y) -> fitted_ensemble`
   - `predict_ensemble(X) -> predictions`

3. **AnomalyDetector** class
   - `detect_isolation_forest(data) -> anomalies`
   - `detect_lstm_autoencoder(data) -> anomalies`
   - `explain_anomalies(anomalies, data) -> explanations`

4. **AdvancedForecaster** class
   - `auto_forecast(series, horizon) -> forecast`
   - `compare_models(series) -> best_model`
   - `ensemble_forecast(series, models) -> forecast`

## TESTES
- Validar acur√°cia AutoML vs modelos manuais
- Testar detec√ß√£o de anomalias (F1-score > 0.8)
- Verificar ensemble performance
- Medir tempo de treino (< 1h para datasets normais)

## FICHEIRO DE SA√çDA
`backend/ml/automl_advanced.py`
```

---

## 6. ‚ö†Ô∏è VISUALIZA√á√ïES E DASHBOARDS AVAN√áADOS

### Status Atual
- ‚ö†Ô∏è Dashboards b√°sicos existem
- ‚ùå Falta: Gantt comparativo, heatmaps interativos, proje√ß√µes visuais

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: DASHBOARDS AVAN√áADOS COM VISUALIZA√á√ïES INTERATIVAS

## CONTEXTO
Implementar dashboards avan√ßados com visualiza√ß√µes comparativas, heatmaps interativos e proje√ß√µes visuais.

## VISUALIZA√á√ïES AVAN√áADAS

### 1. Gantt Comparativo Interativo

**Usar Plotly:**
```python
import plotly.graph_objects as go
from plotly.subplots import make_subplots

def create_comparative_gantt(base_plan, new_plan):
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Plano Base', 'Novo Cen√°rio'),
        vertical_spacing=0.1
    )
    
    # Base plan
    for job in base_plan.jobs:
        fig.add_trace(
            go.Bar(
                x=[job.start, job.duration],
                y=[job.machine],
                name=f"Base: {job.id}",
                marker_color='blue',
                base=job.start
            ),
            row=1, col=1
        )
    
    # New plan
    for job in new_plan.jobs:
        color = 'green' if job.changed else 'orange'
        fig.add_trace(
            go.Bar(
                x=[job.start, job.duration],
                y=[job.machine],
                name=f"New: {job.id}",
                marker_color=color,
                base=job.start
            ),
            row=2, col=1
        )
    
    fig.update_layout(
        title="Compara√ß√£o de Planos",
        xaxis_title="Tempo",
        yaxis_title="M√°quinas",
        height=800
    )
    
    return fig
```

### 2. Heatmap de Utiliza√ß√£o Interativo

```python
def create_utilization_heatmap(machines, time_periods, utilization_data):
    fig = go.Figure(data=go.Heatmap(
        z=utilization_data,
        x=time_periods,
        y=machines,
        colorscale='RdYlGn',
        colorbar=dict(title="Utiliza√ß√£o %"),
        hovertemplate='M√°quina: %{y}<br>Per√≠odo: %{x}<br>Utiliza√ß√£o: %{z}%<extra></extra>'
    ))
    
    fig.update_layout(
        title="Heatmap de Utiliza√ß√£o por M√°quina",
        xaxis_title="Per√≠odo",
        yaxis_title="M√°quinas",
        height=600
    )
    
    return fig
```

### 3. Proje√ß√µes Anuais Visuais

```python
def create_annual_projection(capacity, demand, months):
    fig = go.Figure()
    
    # Capacity line
    fig.add_trace(go.Scatter(
        x=months,
        y=capacity,
        mode='lines+markers',
        name='Capacidade',
        line=dict(color='green', width=2)
    ))
    
    # Demand line
    fig.add_trace(go.Scatter(
        x=months,
        y=demand,
        mode='lines+markers',
        name='Demanda',
        line=dict(color='red', width=2)
    ))
    
    # Fill area between
    fig.add_trace(go.Scatter(
        x=months + months[::-1],
        y=capacity + demand[::-1],
        fill='toself',
        fillcolor='rgba(255,0,0,0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        showlegend=False,
        name='D√©ficit'
    ))
    
    fig.update_layout(
        title="Proje√ß√£o Anual: Capacidade vs Demanda",
        xaxis_title="M√™s",
        yaxis_title="Unidades",
        height=500
    )
    
    return fig
```

### 4. Dashboard de C√©lulas Encadeadas

```python
def create_chain_dashboard(chains_data):
    fig = make_subplots(
        rows=len(chains_data), cols=1,
        subplot_titles=[f"Cadeia {c.id}" for c in chains_data]
    )
    
    for idx, chain in enumerate(chains_data):
        # WIP por m√°quina na cadeia
        machines = chain.machines
        wip_values = [chain.wip[m] for m in machines]
        
        fig.add_trace(
            go.Bar(
                x=machines,
                y=wip_values,
                name=f"WIP - {chain.id}",
                marker_color='steelblue'
            ),
            row=idx+1, col=1
        )
        
        # Throughput
        fig.add_trace(
            go.Scatter(
                x=machines,
                y=chain.throughput,
                mode='lines+markers',
                name=f"Throughput - {chain.id}",
                line=dict(color='orange', width=2),
                yaxis=f'y{idx+2}'
            ),
            row=idx+1, col=1
        )
    
    fig.update_layout(height=300 * len(chains_data))
    return fig
```

## IMPLEMENTA√á√ÉO

### Classes:

1. **AdvancedDashboardGenerator** class
   - `generate_comparative_gantt(base, new) -> Figure`
   - `generate_utilization_heatmap(data) -> Figure`
   - `generate_annual_projection(capacity, demand) -> Figure`
   - `generate_chain_dashboard(chains) -> Figure`

2. **InteractiveVisualizer** class
   - `create_interactive_plot(fig) -> HTML`
   - `export_to_png(fig, filename) -> None`
   - `export_to_pdf(fig, filename) -> None`

## TESTES
- Validar renderiza√ß√£o de gr√°ficos
- Testar interatividade (hover, zoom)
- Verificar exporta√ß√£o (PNG, PDF)
- Medir performance (< 2s para gerar dashboard)

## FICHEIRO DE SA√çDA
`backend/dashboards/advanced_visualizations.py`
```

---

## 7. ‚ùå PLANEAMENTO DE LONGO PRAZO ESTRAT√âGICO

### Status Atual
- ‚ùå **N√ÉO IMPLEMENTADO**
- ‚ö†Ô∏è Existe `backend/dashboards/capacity_projection.py` (b√°sico)

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: PLANEAMENTO ESTRAT√âGICO DE LONGO PRAZO (ANUAL/PLURIANUAL)

## CONTEXTO
Implementar sistema de planeamento estrat√©gico de longo prazo (horizonte anual/plurianual) com simula√ß√£o de investimentos, avalia√ß√£o de capacidade futura e cen√°rios de crescimento.

## MODELO MATEM√ÅTICO ESTRAT√âGICO

### 1. Capacity Planning Multi-Periodo

**Horizonte Temporal:**
- T = {1, ..., T} : Per√≠odos (meses/trimestres)
- T = 12 (anual) ou T = 36 (3 anos)

**Variables:**
- C_{m,t} ‚â• 0 : Capacidade dispon√≠vel da m√°quina m no per√≠odo t
- I_{m,t} ‚àà {0,1} : 1 se investimento em m√°quina m no per√≠odo t
- D_{p,t} ‚â• 0 : Demanda do produto p no per√≠odo t
- P_{p,t} ‚â• 0 : Produ√ß√£o do produto p no per√≠odo t
- S_{p,t} ‚â• 0 : Stock do produto p no per√≠odo t

**Parameters:**
- cap_base_{m} : Capacidade base da m√°quina m
- cap_new_{m} : Capacidade de nova m√°quina m
- cost_inv_{m} : Custo de investimento em m√°quina m
- demand_forecast_{p,t} : Previs√£o de demanda
- growth_rate : Taxa de crescimento anual
- discount_rate : Taxa de desconto

**Constraints:**

(1) Capacity: C_{m,t} = cap_base_{m} + Œ£_{s‚â§t} I_{m,s} ¬∑ cap_new_{m}

(2) Production capacity: Œ£_p P_{p,t} ¬∑ time_{p,m} ‚â§ C_{m,t}  ‚àÄm,t

(3) Demand satisfaction: P_{p,t} + S_{p,t-1} ‚â• D_{p,t} + S_{p,t}  ‚àÄp,t

(4) Stock balance: S_{p,t} = S_{p,t-1} + P_{p,t} - D_{p,t}  ‚àÄp,t

(5) Investment budget: Œ£_{m,t} I_{m,t} ¬∑ cost_inv_{m} ‚â§ budget_t  ‚àÄt

**Objective:**
min Œ£_{m,t} I_{m,t} ¬∑ cost_inv_{m} ¬∑ (1 + discount_rate)^{-t} + 
    Œ£_{p,t} c_shortage ¬∑ max(0, D_{p,t} - P_{p,t} - S_{p,t-1}) +
    Œ£_{p,t} c_holding ¬∑ S_{p,t}

### 2. Demand Forecasting Estrat√©gico

**Modelo de Crescimento:**
D_{p,t} = D_{p,0} ¬∑ (1 + growth_rate_p)^{t/12} ¬∑ seasonality_{t mod 12}

**Sazonalidade:**
seasonality_{m} = 1 + A ¬∑ sin(2œÄm/12 + œÜ)

**Uncertainty:**
D_{p,t} ~ Normal(Œº_{p,t}, œÉ_{p,t})

Onde œÉ_{p,t} = Œº_{p,t} ¬∑ CV (coefficient of variation)

### 3. Investment Optimization

**NPV Calculation:**
NPV = Œ£_{t=0}^{T} (CashFlow_t) / (1 + r)^t

**ROI:**
ROI = (Total_Benefits - Total_Cost) / Total_Cost ¬∑ 100

**Payback Period:**
Payback = min{t | Œ£_{s=0}^{t} CashFlow_s ‚â• 0}

### 4. Scenario Analysis

**Cen√°rios:**
- Baseline: crescimento 5%
- Optimistic: crescimento 10%
- Pessimistic: crescimento 2%
- Stagflation: crescimento 0%, infla√ß√£o alta

**Monte Carlo Simulation:**
```python
def monte_carlo_scenario(demand_dist, capacity_options, n_simulations=1000):
    results = []
    for _ in range(n_simulations):
        # Sample demanda
        demand_sample = demand_dist.sample()
        
        # Calcular capacidade necess√°ria
        required_capacity = calculate_required_capacity(demand_sample)
        
        # Escolher investimento √≥timo
        investment = optimize_investment(required_capacity, capacity_options)
        
        # Calcular NPV
        npv = calculate_npv(investment, demand_sample)
        results.append(npv)
    
    return {
        'mean_npv': np.mean(results),
        'std_npv': np.std(results),
        'p5_npv': np.percentile(results, 5),
        'p95_npv': np.percentile(results, 95)
    }
```

## IMPLEMENTA√á√ÉO

### Classes:

1. **StrategicPlanner** class
   - `create_strategic_plan(horizon_years, demand_forecast) -> StrategicPlan`
   - `optimize_investments(capacity_options, budget) -> InvestmentPlan`
   - `evaluate_scenarios(scenarios) -> ScenarioComparison`

2. **LongTermForecaster** class
   - `forecast_demand(historical_data, growth_rate, horizon) -> DemandForecast`
   - `add_seasonality(forecast, seasonality_params) -> Forecast`
   - `add_uncertainty(forecast, cv) -> ProbabilisticForecast`

3. **InvestmentOptimizer** class
   - `optimize_capacity_investments(demand, options, budget) -> InvestmentPlan`
   - `calculate_npv(investment, cashflows, discount_rate) -> float`
   - `calculate_roi(investment, benefits) -> float`

4. **ScenarioAnalyzer** class
   - `create_scenarios(base_forecast, variations) -> List[Scenario]`
   - `monte_carlo_simulation(scenarios, n_simulations) -> MCResults`
   - `compare_scenarios(scenarios) -> ComparisonReport`

## TESTES
- Validar previs√µes de longo prazo (backtesting)
- Testar otimiza√ß√£o de investimentos (valida√ß√£o com Excel)
- Verificar cen√°rios (sanity check)
- Medir tempo de c√°lculo (< 5min para 3 anos)

## FICHEIRO DE SA√çDA
`backend/planning/strategic_planner.py`
```

---

## 8. ‚ö†Ô∏è INTEGRA√á√ÉO ERP/MES BIDIRECIONAL AVAN√áADA

### Status Atual
- ‚ö†Ô∏è B√°sico existe em `backend/integration/erp_mes_connector.py`
- ‚ùå Falta: Sincroniza√ß√£o em tempo real, APIs RESTful, webhooks

### üéØ PROMPT SUPER INOVADOR

```
# PROMPT: INTEGRA√á√ÉO ERP/MES BIDIRECIONAL COM SINCRONIZA√á√ÉO EM TEMPO REAL

## CONTEXTO
Implementar integra√ß√£o bidirecional avan√ßada com ERP/MES, incluindo sincroniza√ß√£o em tempo real, APIs RESTful e webhooks.

## ARQUITETURA DE INTEGRA√á√ÉO

### 1. Data Synchronization Protocol

**Change Data Capture (CDC):**
- Monitorar mudan√ßas em ERP/MES
- Usar triggers SQL ou polling
- Aplicar apenas mudan√ßas incrementais

**Conflict Resolution:**
- Last-Write-Wins (LWW)
- Timestamp-based
- Version vectors para resolu√ß√£o distribu√≠da

### 2. RESTful API Design

**Endpoints:**

```
POST /api/integration/erp/import-orders
GET  /api/integration/erp/orders
POST /api/integration/erp/export-plan
GET  /api/integration/mes/status
POST /api/integration/mes/update-execution
GET  /api/integration/mes/machine-status
```

**Data Models:**
```python
class ERPOrder:
    order_id: str
    product_id: str
    quantity: int
    due_date: datetime
    priority: str
    status: str

class MESExecution:
    operation_id: str
    machine_id: str
    start_time: datetime
    end_time: Optional[datetime]
    status: str  # running, completed, stopped
    actual_duration: Optional[float]
```

### 3. Webhook System

**Event Types:**
- order_created
- order_updated
- order_cancelled
- execution_started
- execution_completed
- machine_down
- material_shortage

**Webhook Handler:**
```python
class WebhookHandler:
    def handle_order_created(self, event):
        order = parse_order(event.data)
        self.aps.add_order(order)
        self.aps.replan()
    
    def handle_execution_completed(self, event):
        execution = parse_execution(event.data)
        self.aps.update_execution_status(execution)
        self.aps.adjust_plan()
```

### 4. Real-Time Synchronization

**WebSocket Connection:**
```python
import websocket
import json

class RealTimeSync:
    def __init__(self, erp_url, mes_url):
        self.erp_ws = websocket.WebSocketApp(
            erp_url,
            on_message=self.on_erp_message
        )
        self.mes_ws = websocket.WebSocketApp(
            mes_url,
            on_message=self.on_mes_message
        )
    
    def on_erp_message(self, ws, message):
        data = json.loads(message)
        if data['type'] == 'order_update':
            self.aps.update_order(data['order'])
    
    def on_mes_message(self, ws, message):
        data = json.loads(message)
        if data['type'] == 'execution_update':
            self.aps.update_execution(data['execution'])
```

## IMPLEMENTA√á√ÉO

### Classes:

1. **ERPConnector** class
   - `import_orders(query_params) -> List[Order]`
   - `export_plan(plan) -> ExportResult`
   - `sync_orders() -> SyncResult`

2. **MESConnector** class
   - `get_execution_status(operation_id) -> ExecutionStatus`
   - `update_execution(execution) -> UpdateResult`
   - `get_machine_status(machine_id) -> MachineStatus`

3. **WebhookManager** class
   - `register_webhook(event_type, url) -> Webhook`
   - `trigger_webhook(event) -> None`
   - `handle_incoming_webhook(request) -> Response`

4. **RealTimeSyncManager** class
   - `connect_erp(url) -> Connection`
   - `connect_mes(url) -> Connection`
   - `handle_realtime_update(update) -> None`

## TESTES
- Testar importa√ß√£o de ordens (valida√ß√£o de dados)
- Verificar exporta√ß√£o de planos (formato correto)
- Testar webhooks (end-to-end)
- Validar sincroniza√ß√£o em tempo real (lat√™ncia < 1s)

## FICHEIRO DE SA√çDA
`backend/integration/advanced_erp_mes_connector.py`
```

---

## üìä RESUMO DE STATUS E PRIORIDADES

| # | Funcionalidade | Status | Prioridade | Ficheiros a Criar |
|---|---------------|--------|------------|-------------------|
| 1 | Planeamento Encadeado Avan√ßado | ‚ö†Ô∏è Parcial | Alta | `chained_scheduler_advanced.py` |
| 2 | LLM Local com LoRA | ‚ö†Ô∏è B√°sico | Alta | `lora_trainer.py`, `vector_store.py`, `rag_engine.py` |
| 3 | What-If Conversacional | ‚ö†Ô∏è B√°sico | Alta | `whatif_advanced.py` |
| 4 | Relat√≥rios Autom√°ticos | ‚ö†Ô∏è Parcial | M√©dia | `llm_report_generator.py` |
| 5 | AutoML Avan√ßado | ‚ö†Ô∏è Parcial | M√©dia | `automl_advanced.py` |
| 6 | Dashboards Avan√ßados | ‚ö†Ô∏è Parcial | M√©dia | `advanced_visualizations.py` |
| 7 | Planeamento Estrat√©gico | ‚ùå N√£o existe | Alta | `strategic_planner.py` |
| 8 | Integra√ß√£o ERP/MES | ‚ö†Ô∏è B√°sico | M√©dia | `advanced_erp_mes_connector.py` |

---

## üéØ PR√ìXIMOS PASSOS

1. **Implementar Planeamento Estrat√©gico** (prioridade m√°xima - n√£o existe)
2. **Melhorar LLM Local** (adicionar LoRA, vector DB)
3. **Avan√ßar What-If Conversacional** (parser NL avan√ßado)
4. **Completar AutoML** (H2O.ai integration)
5. **Melhorar Dashboards** (visualiza√ß√µes interativas)

---

**Todos os prompts acima s√£o super detalhados, com modelos matem√°ticos avan√ßados e implementa√ß√µes inovadoras!** üöÄ

